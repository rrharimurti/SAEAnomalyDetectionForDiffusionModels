{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0935400",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch datasets transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19597a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a23149",
   "metadata": {},
   "source": [
    "## Load BeaverTails Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af86e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"PKU-Alignment/BeaverTails\", split=\"30k_train\")\n",
    "\n",
    "benign_prompts = [ex[\"prompt\"] for ex in ds if ex[\"is_safe\"]]\n",
    "jailbreak_prompts = [ex[\"prompt\"] for ex in ds if not ex[\"is_safe\"]]\n",
    "\n",
    "print(f\"Training on {len(benign_prompts)} benign prompts\")\n",
    "print(f\"Testing on {len(jailbreak_prompts)} jailbreak prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d9883",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"GSAI-ML/LLaDA-8B-Instruct\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    output_hidden_states=True,\n",
    ").to(device).eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"GSAI-ML/LLaDA-8B-Instruct\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c62f7",
   "metadata": {},
   "source": [
    "## Torch Dataset for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptDataset(Dataset):\n",
    "    def __init__(self, prompts, tokenizer):\n",
    "        # Pre-tokenize once, apply chat template\n",
    "        self.examples = [\n",
    "            tokenizer.apply_chat_template(\n",
    "                [{\"role\": \"user\", \"content\": p}],\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=False\n",
    "            )\n",
    "            for p in prompts\n",
    "        ]\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac647075",
   "metadata": {},
   "source": [
    "## Encode Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(prompts, batch_size=32):\n",
    "    dataset = PromptDataset(prompts, tokenizer)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    all_embeds = []\n",
    "\n",
    "    for i, inputs in enumerate(loader):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            # hidden_states is a tuple: (layer, batch, seq, dim)\n",
    "            hidden_states = torch.stack(outputs.hidden_states)  # [n_layers, batch, seq, dim]\n",
    "            # Treat each token embedding as one training sample\n",
    "            embeds = outputs.hidden_states[-2].reshape(-1, hidden_dim)  # [(batch*seq), dim]\n",
    "            all_embeds.append(embeds.cpu())\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{i * batch_size}/{len(prompts)} prompts done\")\n",
    "\n",
    "    return torch.cat(all_embeds, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015531cc",
   "metadata": {},
   "source": [
    "## Run for Benign/Jailbreak Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Encoding benign prompts...\")\n",
    "benign_embeds = encode_dataset(benign_prompts)\n",
    "\n",
    "print(\"Encoding jailbreak prompts...\")\n",
    "jailbreak_embeds = encode_dataset(jailbreak_prompts)\n",
    "\n",
    "print(\"Shapes:\", benign_embeds.shape, jailbreak_embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542040e4",
   "metadata": {},
   "source": [
    "## Define SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = torch.relu(self.encoder(x))\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0967607",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = benign_embeds.shape[1]\n",
    "hidden_dim = 512\n",
    "\n",
    "sae = SparseAutoencoder(input_dim, hidden_dim).to(device, dtype=torch.bfloat16)\n",
    "optimizer = torch.optim.Adam(sae.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def sparsity_loss(z, lam=1e-5):\n",
    "    return lam * torch.mean(torch.abs(z))\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(benign_embeds.to(device, dtype=torch.bfloat16)), batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(50):\n",
    "    sae.train()\n",
    "    for (batch,) in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        x_hat, z = sae(batch)\n",
    "        loss = criterion(x_hat, batch) + sparsity_loss(z)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53d271",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346240d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae.eval()\n",
    "\n",
    "def reconstruction_error(x):\n",
    "    with torch.no_grad():\n",
    "        x_hat, _ = sae(x.to(device))\n",
    "        return torch.mean((x_hat - x.to(device))**2, dim=1).cpu()\n",
    "\n",
    "benign_errors = reconstruction_error(benign_embeds)\n",
    "jailbreak_errors = reconstruction_error(jailbreak_embeds)\n",
    "\n",
    "print(f\"Avg benign error:   {benign_errors.mean():.4f}\")\n",
    "print(f\"Avg jailbreak error:{jailbreak_errors.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
